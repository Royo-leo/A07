import os
import cv2
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from glob import glob
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm import tqdm  # æ–°å¢è¿›åº¦æ¡åº“

# ==================== é…ç½®å‚æ•° ====================
DATA_DIR = "./Train"  # åŒ…å«imageså’Œmaskså­ç›®å½•çš„è·¯å¾„
TARGET_SIZE = 512     # ç›®æ ‡å°ºå¯¸
BATCH_SIZE = 4
EPOCHS = 10
LR = 1e-4
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def get_preprocess():
    return A.Compose([
        A.Resize(TARGET_SIZE, TARGET_SIZE),  # ç»Ÿä¸€è°ƒæ•´ä¸º512x512
        A.Normalize(mean=(0.485, 0.456, 0.406),
                   std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ], is_check_shapes=False)

# ==================== æ•°æ®å‡†å¤‡ ====================
class RetinaDataset(Dataset):
    def __init__(self, image_paths, mask_paths):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.preprocess = get_preprocess()

        # é¢„éªŒè¯æ•°æ®è´¨é‡
        self._validate_dataset()

    def _validate_dataset(self):
        """æ‰§è¡Œä¸¥æ ¼çš„æ•°æ®éªŒè¯"""
        print("\nğŸ” æ­£åœ¨éªŒè¯æ•°æ®é›†...")
        for idx in tqdm(range(len(self)), desc="æ•°æ®éªŒè¯è¿›åº¦"):
            img_path = self.image_paths[idx]
            mask_path = self.mask_paths[idx]

            # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
            if not os.path.exists(img_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ç¼ºå¤±: {img_path}")
            if not os.path.exists(mask_path):
                raise FileNotFoundError(f"æ©è†œæ–‡ä»¶ç¼ºå¤±: {mask_path}")

        print("âœ… æ•°æ®é›†éªŒè¯é€šè¿‡")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # è¯»å–å¹¶é¢„å¤„ç†å›¾åƒ
        image = cv2.cvtColor(cv2.imread(self.image_paths[idx]), cv2.COLOR_BGR2RGB)

        # è¯»å–å¹¶é¢„å¤„ç†æ©è†œï¼ˆä¿æŒäºŒå€¼ç‰¹æ€§ï¼‰
        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)
        mask = (mask > 127).astype(np.float32)  # ç›´æ¥ç”Ÿæˆ0/1çŸ©é˜µ

        # åº”ç”¨é¢„å¤„ç†
        processed = self.preprocess(image=image, mask=mask)
        img_tensor = processed["image"]
        mask_tensor = processed["mask"].float()

        # æœ€ç»ˆå°ºå¯¸éªŒè¯
        assert img_tensor.shape[1:] == (TARGET_SIZE, TARGET_SIZE), "å›¾åƒå°ºå¯¸é”™è¯¯"
        assert mask_tensor.shape == (TARGET_SIZE, TARGET_SIZE), "æ©è†œå°ºå¯¸é”™è¯¯"

        return img_tensor, mask_tensor

# ==================== æ¨¡å‹å®šä¹‰ ====================
class UNet(nn.Module):
    def __init__(self):
        super().__init__()

        def double_conv(in_c, out_c):
            return nn.Sequential(
                nn.Conv2d(in_c, out_c, 3, padding=1),
                nn.BatchNorm2d(out_c),
                nn.ReLU(inplace=True),
                nn.Conv2d(out_c, out_c, 3, padding=1),
                nn.BatchNorm2d(out_c),
                nn.ReLU(inplace=True)
            )

        # ç¼–ç å™¨
        self.down1 = double_conv(3, 64)
        self.down2 = double_conv(64, 128)
        self.down3 = double_conv(128, 256)
        self.pool = nn.MaxPool2d(2)

        # ç“¶é¢ˆå±‚
        self.bottleneck = double_conv(256, 512)

        # è§£ç å™¨
        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)
        self.up_conv3 = double_conv(512, 256)
        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)
        self.up_conv2 = double_conv(256, 128)
        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)
        self.up_conv1 = double_conv(128, 64)

        # è¾“å‡ºå±‚
        self.out = nn.Conv2d(64, 1, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # ç¼–ç 
        c1 = self.down1(x)  # [B,64,H,W]
        p1 = self.pool(c1)
        c2 = self.down2(p1)  # [B,128,H/2,W/2]
        p2 = self.pool(c2)
        c3 = self.down3(p2)  # [B,256,H/4,W/4]
        p3 = self.pool(c3)

        # ç“¶é¢ˆ
        bn = self.bottleneck(p3)  # [B,512,H/8,W/8]

        # è§£ç 
        u3 = self.up3(bn)  # [B,256,H/4,W/4]
        u3 = torch.cat([u3, c3], dim=1)
        u3 = self.up_conv3(u3)

        u2 = self.up2(u3)  # [B,128,H/2,W/2]
        u2 = torch.cat([u2, c2], dim=1)
        u2 = self.up_conv2(u2)

        u1 = self.up1(u2)  # [B,64,H,W]
        u1 = torch.cat([u1, c1], dim=1)
        u1 = self.up_conv1(u1)

        return self.sigmoid(self.out(u1))


# ==================== è®­ç»ƒå‡½æ•° ====================
def train():
    # æ•°æ®è·¯å¾„å¤„ç†
    image_dir = os.path.join(DATA_DIR, "images")
    mask_dir = os.path.join(DATA_DIR, "masks")

    # è·å–æ’åºåçš„æ–‡ä»¶åˆ—è¡¨
    image_files = sorted(glob(os.path.join(image_dir, "*.jpg")))  
    mask_files = sorted(glob(os.path.join(mask_dir, "*.bmp")))  

    # æ£€æŸ¥å›¾åƒå’Œæ©è†œæ•°é‡æ˜¯å¦åŒ¹é…
    if len(image_files) != len(mask_files):
        raise ValueError(f"å›¾åƒæ•°é‡å’Œæ©è†œæ•°é‡ä¸åŒ¹é…: {len(image_files)} vs {len(mask_files)}")

    # åˆ›å»ºæ•°æ®é›†
    train_ds = RetinaDataset(image_files[:int(0.8 * len(image_files))],
                             mask_files[:int(0.8 * len(mask_files))])
    val_ds = RetinaDataset(image_files[int(0.8 * len(image_files)):],
                           mask_files[int(0.8 * len(mask_files)):])

    # æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,
                              shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE,
                            num_workers=4, pin_memory=True)

    # æ¨¡å‹åˆå§‹åŒ–
    model = UNet().to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    criterion = nn.BCELoss()

    # è®­ç»ƒå¾ªç¯
    best_dice = 0.0
    for epoch in range(EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [Train]")
        for images, masks in train_bar:
            images, masks = images.to(DEVICE), masks.unsqueeze(1).to(DEVICE)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()

            train_bar.set_postfix(loss=f"{loss.item():.4f}")

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss, dice_score = 0.0, 0.0
        with torch.no_grad():
            val_bar = tqdm(val_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [Val]")
            for images, masks in val_bar:
                images, masks = images.to(DEVICE), masks.unsqueeze(1).to(DEVICE)

                outputs = model(images)
                val_loss += criterion(outputs, masks).item()

                preds = (outputs > 0.5).float()
                intersection = (preds * masks).sum()
                union = preds.sum() + masks.sum()
                dice = 2 * intersection / (union + 1e-8)
                dice_score += dice.item()

                val_bar.set_postfix(dice=f"{dice.item():.4f}")

        # æ¨¡å‹ä¿å­˜é€»è¾‘
        avg_dice = dice_score / len(val_loader)
        if avg_dice > best_dice:
            best_dice = avg_dice
            torch.save(model.state_dict(), "best_model.pth")
            print(f"\nğŸ”¥ å‘ç°æ–°æœ€ä½³æ¨¡å‹ Diceç³»æ•°: {best_dice:.4f}")

# ==================== é¢„æµ‹å‡½æ•° ====================
def predict(image_path, model_path="best_model.pth"):
    # åŠ è½½æ¨¡å‹
    model = UNet().to(DEVICE)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    # è¯»å–å¹¶é¢„å¤„ç†
    image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)
    orig_h, orig_w = image.shape[:2]

    preprocess = get_preprocess()
    processed = preprocess(image=image)
    input_tensor = processed["image"].unsqueeze(0).to(DEVICE)

    # æ¨ç†
    with torch.no_grad():
        output = model(input_tensor)

    # åå¤„ç†
    mask = (output.squeeze().cpu().numpy() > 0.5).astype(np.uint8)

    # è¿˜åŸåˆ°åŸå§‹å°ºå¯¸
    final_mask = cv2.resize(mask, (orig_w, orig_h),
                            interpolation=cv2.INTER_NEAREST) * 255
    return final_mask


if __name__ == "__main__":

    train()

    test_image = "./Train/images/H0001.jpg"  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    result_mask = predict(test_image)

    cv2.imwrite("predicted_mask.png", result_mask)
    print("Prediction saved to predicted_mask.png")
